{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef97521",
   "metadata": {},
   "source": [
    "\n",
    "# Model Deployment for House Prices Prediction\n",
    "\n",
    "## 1. Introduction\n",
    "In this notebook, we will:\n",
    "1. Load the saved models from the model building process.\n",
    "2. Apply the same feature engineering steps to the `test.csv` data as we did for the training set.\n",
    "3. Ensure that the test dataset's features are aligned with the training dataset by adding any missing columns.\n",
    "4. Run predictions using the models on the test set and save them in the required submission format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13288a5a",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Loading the Saved Models and Training Columns\n",
    "We will load the saved Random Forest, Gradient Boosting, and tuned Gradient Boosting models, as well as the saved column names from the training dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "041d46f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and training columns loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "# Load the saved models and training column names\n",
    "loaded_rf = joblib.load('random_forest_model.pkl')\n",
    "loaded_gb = joblib.load('gradient_boosting_model.pkl')\n",
    "loaded_best_gb = joblib.load('tuned_gradient_boosting_model.pkl')\n",
    "train_columns = joblib.load('train_columns.pkl')  # Load saved training columns\n",
    "\n",
    "print(\"Models and training columns loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b02636",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Loading and Applying Feature Engineering to `test.csv` (with Feature Alignment)\n",
    "We will load the test dataset (`test.csv`), apply the same feature engineering steps, and ensure that the features match those used during training by adding any missing columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7356a601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>TotalSF</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.363929</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.954072</td>\n",
       "      <td>0.413784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.897861</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.164507</td>\n",
       "      <td>0.512398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.809646</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.036124</td>\n",
       "      <td>-0.769577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.032064</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>-0.802448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-0.971808</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.039938</td>\n",
       "      <td>-0.605221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  \\\n",
       "0  1461          20         80.0  0.363929            5            6   \n",
       "1  1462          20         81.0  0.897861            6            6   \n",
       "2  1463          60         74.0  0.809646            5            5   \n",
       "3  1464          60         78.0  0.032064            6            6   \n",
       "4  1465         120         43.0 -0.971808            8            5   \n",
       "\n",
       "   YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  SaleType_New  \\\n",
       "0       1961          1961         0.0       468.0  ...         False   \n",
       "1       1958          1958       108.0       923.0  ...         False   \n",
       "2       1997          1998         0.0       791.0  ...         False   \n",
       "3       1998          1998        20.0       602.0  ...         False   \n",
       "4       1992          1992         0.0       263.0  ...         False   \n",
       "\n",
       "   SaleType_Oth  SaleType_WD  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0         False         True                  False                 False   \n",
       "1         False         True                  False                 False   \n",
       "2         False         True                  False                 False   \n",
       "3         False         True                  False                 False   \n",
       "4         False         True                  False                 False   \n",
       "\n",
       "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \\\n",
       "0                 False                  True                  False   \n",
       "1                 False                  True                  False   \n",
       "2                 False                  True                  False   \n",
       "3                 False                  True                  False   \n",
       "4                 False                  True                  False   \n",
       "\n",
       "    TotalSF       Age  \n",
       "0 -0.954072  0.413784  \n",
       "1  0.164507  0.512398  \n",
       "2  0.036124 -0.769577  \n",
       "3  0.001804 -0.802448  \n",
       "4  0.039938 -0.605221  \n",
       "\n",
       "[5 rows x 267 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# 1. Handle missing values (same as training set)\n",
    "numerical_with_nan = [feature for feature in test_data.columns if test_data[feature].isnull().sum() > 0 and test_data[feature].dtypes != 'O']\n",
    "categorical_with_nan = [feature for feature in test_data.columns if test_data[feature].isnull().sum() > 0 and test_data[feature].dtypes == 'O']\n",
    "\n",
    "# Impute missing values for numerical features with the median\n",
    "for feature in numerical_with_nan:\n",
    "    median_value = test_data[feature].median()\n",
    "    test_data.loc[:, feature + '_nan'] = np.where(test_data[feature].isnull(), 1, 0)  # Use .loc[] to avoid chaining\n",
    "    test_data.loc[:, feature] = test_data[feature].fillna(median_value)\n",
    "\n",
    "# Impute missing values with the mode for categorical features\n",
    "for feature in categorical_with_nan:\n",
    "    mode_value = test_data[feature].mode()[0]\n",
    "    test_data.loc[:, feature + '_nan'] = np.where(test_data[feature].isnull(), 1, 0)\n",
    "    test_data.loc[:, feature] = test_data[feature].fillna(mode_value)\n",
    "\n",
    "# 2. Encoding categorical features (one-hot encoding as in training set)\n",
    "categorical_features = [feature for feature in test_data.columns if test_data[feature].dtype == 'O']\n",
    "test_data_encoded = pd.get_dummies(test_data, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# 3. Creating new features (e.g., Age, TotalSF)\n",
    "test_data_encoded['TotalSF'] = test_data_encoded['TotalBsmtSF'] + test_data_encoded['1stFlrSF'] + test_data_encoded['2ndFlrSF']\n",
    "test_data_encoded['Age'] = test_data_encoded['YrSold'] - test_data_encoded['YearBuilt']\n",
    "\n",
    "# 4. Feature scaling (apply the same scaling as in training set)\n",
    "numerical_features_to_scale = ['LotArea', 'GrLivArea', 'TotalSF', 'Age']\n",
    "scaler = StandardScaler()\n",
    "test_data_encoded[numerical_features_to_scale] = scaler.fit_transform(test_data_encoded[numerical_features_to_scale])\n",
    "\n",
    "# Align the test dataset with the training dataset's features\n",
    "for col in train_columns:\n",
    "    if col not in test_data_encoded.columns:\n",
    "        test_data_encoded[col] = 0  # Add missing columns with 0s\n",
    "\n",
    "# Ensure the test dataset has only the columns the model expects\n",
    "test_data_encoded = test_data_encoded[train_columns]\n",
    "\n",
    "# Preview the aligned test data\n",
    "test_data_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e97a7d",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Making Predictions using the Loaded Models\n",
    "We will use the loaded models to make predictions on the aligned test data (`test.csv`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e122dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Predictions: [124922.83 167684.56 181902.29 189358.5  209899.46]\n",
      "Gradient Boosting Predictions: [123127.33932033 159790.25023812 193302.5972056  189742.05597774\n",
      " 180714.77470896]\n",
      "Tuned Gradient Boosting Predictions: [123198.5565692  160405.23452153 195114.6230271  191109.26418761\n",
      " 177549.25069156]\n"
     ]
    }
   ],
   "source": [
    "# Ensure that SalePrice is not in the test dataset\n",
    "if 'SalePrice' in test_data_encoded.columns:\n",
    "    test_data_encoded = test_data_encoded.drop('SalePrice', axis=1)\n",
    "    \n",
    "# Use the loaded models to make predictions on the aligned test set\n",
    "rf_predictions = loaded_rf.predict(test_data_encoded)\n",
    "gb_predictions = loaded_gb.predict(test_data_encoded)\n",
    "best_gb_predictions = loaded_best_gb.predict(test_data_encoded)\n",
    "\n",
    "# Display the first few predictions from each model\n",
    "print(f\"Random Forest Predictions: {rf_predictions[:5]}\")\n",
    "print(f\"Gradient Boosting Predictions: {gb_predictions[:5]}\")\n",
    "print(f\"Tuned Gradient Boosting Predictions: {best_gb_predictions[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d12172",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Saving the Predictions in Submission Format\n",
    "We will save the predictions to CSV files in the required submission format: `Id,SalePrice`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33edb519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in submission format as 'rf_predictions_submission.csv', 'gb_predictions_submission.csv', and 'best_gb_predictions_submission.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a DataFrame for predictions\n",
    "rf_results = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': rf_predictions})\n",
    "gb_results = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': gb_predictions})\n",
    "best_gb_results = pd.DataFrame({'Id': test_data['Id'], 'SalePrice': best_gb_predictions})\n",
    "\n",
    "# Save the predictions to CSV files in submission format\n",
    "rf_results.to_csv('rf_predictions_submission.csv', index=False)\n",
    "gb_results.to_csv('gb_predictions_submission.csv', index=False)\n",
    "best_gb_results.to_csv('best_gb_predictions_submission.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved in submission format as 'rf_predictions_submission.csv', 'gb_predictions_submission.csv', and 'best_gb_predictions_submission.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c5082e",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Summary and Next Steps\n",
    "In this notebook, we:\n",
    "1. Loaded the saved models and the feature columns from the training dataset.\n",
    "2. Applied the same feature engineering steps to the `test.csv` data as we did for the training data.\n",
    "3. Ensured the test dataset's features match the training set by adding any missing columns.\n",
    "4. Ran the models on the aligned test data and saved the predictions in the required submission format.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
